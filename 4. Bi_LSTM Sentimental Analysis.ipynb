{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. Bi_LSTM Sentimental Analysis.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP5Snk7r9PvrtcJchLrh8nC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1lQiKI84bOxP","colab_type":"text"},"source":["# **Check the Sentimental Analysis function**"]},{"cell_type":"code","metadata":{"id":"_wqU1ek2CRt3","colab_type":"code","outputId":"358d802a-8216-4616-ac17-2062e2d777b2","executionInfo":{"status":"ok","timestamp":1587485185948,"user_tz":-540,"elapsed":28839,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JXQziFFJCTup","colab_type":"code","outputId":"4757a69c-69bd-4fbc-f8fe-37b1941a1922","executionInfo":{"status":"ok","timestamp":1587485194450,"user_tz":-540,"elapsed":7809,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":600}},"source":["!pip install konlpy"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 235kB/s \n","\u001b[?25hCollecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.2)\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 11.0MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/3c/1dbe5d6943b5c68e8df17c8b3a05db4725eadb5c7b7de437506aa3030701/JPype1-0.7.2-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n","\u001b[K     |████████████████████████████████| 2.4MB 46.8MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n","Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2020.4.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Installing collected packages: tweepy, beautifulsoup4, JPype1, colorama, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-0.7.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5v9iW4P3CX9y","colab_type":"code","outputId":"79c372db-861e-4fb6-c234-3510336d07d6","executionInfo":{"status":"ok","timestamp":1587485202420,"user_tz":-540,"elapsed":5885,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x\n","import os\n","import tensorflow as tf\n","from konlpy.tag import Okt\n","\n","import gensim\n","import numpy as np"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UlKI-FfXDN2r","colab_type":"code","colab":{}},"source":["class Word2Vec():\n","    \n","    def __init__(self):\n","        None\n","\n","    def tokenize(self, doc): # 토크나이즈 하는 부분\n","        pos_tagger = Okt()\n","        return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)] # 품사 테깅하는 부분\n","    \n","    def read_data(self, filename): # 데이터 읽는 부분 \n","        with open(filename, 'r',encoding='utf-8') as f:\n","            data = [line.split('\\t') for line in f.read().splitlines()]\n","            data = data[1:]\n","        return data  \n","    \n","    def Word2vec_model(self, model_name): # word2vec gensim모델을 불러들이는 부분\n","        model = gensim.models.word2vec.Word2Vec.load(model_name)\n","        return model\n","    \n","    # 한글 단어를 미리 프리트레이닝된 word2vec 모델에 lookup 테이블을 통해서 불러들이는 부분\n","    # 워드를 벡터로 바꾸는 부분\n","    def Convert2Vec(self, model_name, doc):  # Convert corpus into vectors\n","        word_vec = []\n","        model = gensim.models.word2vec.Word2Vec.load(model_name)\n","        for sent in doc:\n","            sub = []\n","            for word in sent: # 단어가 트레이닝된 단어장에 있으면 벡터를 불러들이고\n","                if(word in model.wv.vocab):\n","                    sub.append(model.wv[word])\n","                else: # 없다면 유니폼 분포를 따르는 어떤 램덤한 벡터를 생성하게 된다. 즉, OOV가 된다\n","                    sub.append(np.random.uniform(-0.25,0.25,300)) ## used for Out Of Vocaburaly words\n","            word_vec.append(sub)\n","        \n","        return np.array(word_vec)\n","    \n","    # 단어 사전에 제일 긴 단어길이에 맞춰 다른 단어들도 0으로 채워주기 위한 함수\n","    def Zero_padding(self, train_batch_X, Batch_size, Maxseq_length, Vector_size):\n","        zero_pad = np.zeros((Batch_size, Maxseq_length, Vector_size))\n","        for i in range(Batch_size):\n","            zero_pad[i,:np.shape(train_batch_X[i])[0],:np.shape(train_batch_X[i])[1]] = train_batch_X[i]\n","            \n","        return zero_pad\n","    \n","    # 원핫인코딩 기법\n","    def One_hot(self, data):\n","        index_dict = {value:index for index,value in enumerate(set(data))}\n","        result = []\n","        \n","        for value in data:\n","            one_hot = np.zeros(len(index_dict))\n","            index = index_dict[value]\n","            one_hot[index] = 1\n","            result.append(one_hot)\n","        \n","        return np.array(result)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6A34G5OCcEv","colab_type":"code","colab":{}},"source":["class Bi_LSTM():\n","\n","    def __init__(self, lstm_units, num_class, keep_prob):\n","        self.lstm_units = lstm_units\n","\n","        with tf.variable_scope('forward', reuse=tf.AUTO_REUSE):\n","            self.lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(lstm_units, forget_bias=1.0, state_is_tuple=True)\n","            self.lstm_fw_cell = tf.contrib.rnn.DropoutWrapper(self.lstm_fw_cell, output_keep_prob=keep_prob)\n","\n","        with tf.variable_scope('backward', reuse=tf.AUTO_REUSE):\n","            self.lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(lstm_units, forget_bias=1.0, state_is_tuple=True)\n","            self.lstm_bw_cell = tf.contrib.rnn.DropoutWrapper(self.lstm_bw_cell, output_keep_prob=keep_prob)\n","\n","        with tf.variable_scope('Weights', reuse=tf.AUTO_REUSE):\n","            self.W = tf.get_variable(name=\"W\", shape=[2 * lstm_units, num_class],\n","                                     dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n","            self.b = tf.get_variable(name=\"b\", shape=[num_class], dtype=tf.float32,\n","                                     initializer=tf.zeros_initializer())\n","\n","    def logits(self, X, W, b, seq_len):\n","        (output_fw, output_bw), states = tf.nn.bidirectional_dynamic_rnn(self.lstm_fw_cell, self.lstm_bw_cell,\n","                                                                         dtype=tf.float32,\n","                                                                         inputs=X, sequence_length=seq_len)\n","        # concat fw, bw \n","        outputs = tf.concat([states[0][1], states[1][1]], axis=1) # final states\n","        # final state를 fully connected layer를 통해서 prediction하게 된다.\n","        pred = tf.matmul(outputs, W) + b # softmax\n","        return pred\n","\n","    def model_build(self, logits, labels, learning_rate=0.001):\n","        with tf.variable_scope(\"loss\"):\n","            loss = tf.reduce_mean(\n","                tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))  # Softmax loss\n","            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)  # Adam Optimizer\n","        return loss, optimizer\n","\n","    # Tensorboard를 통해 그래프를 만들때 쓰는 부분\n","    def graph_build(self):\n","        self.loss = tf.placeholder(tf.float32)\n","        self.acc = tf.placeholder(tf.float32)\n","        tf.summary.scalar('Loss', self.loss)\n","        tf.summary.scalar('Accuracy', self.acc)\n","        merged = tf.summary.merge_all()\n","        return merged"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gUONJGAbCfko","colab_type":"code","colab":{}},"source":["W2V = Word2Vec()\n","\n","Batch_size = 1\n","Vector_size = 300\n","Maxseq_length = 95   ## Max length of training data\n","learning_rate = 0.001\n","lstm_units = 128\n","num_class = 2\n","keep_prob = 1.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SwrvbosqCh9C","colab_type":"code","colab":{}},"source":["X = tf.placeholder(tf.float32, shape = [None, Maxseq_length, Vector_size], name = 'X')\n","Y = tf.placeholder(tf.float32, shape = [None, num_class], name = 'Y')\n","seq_len = tf.placeholder(tf.int32, shape = [None])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BXq8C6XnCkm8","colab_type":"code","outputId":"f4d14d02-3d9f-4104-bde6-4a877cf63165","executionInfo":{"status":"ok","timestamp":1587485214073,"user_tz":-540,"elapsed":2981,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":494}},"source":["BiLSTM = Bi_LSTM(lstm_units, num_class, keep_prob)\n","\n","with tf.variable_scope(\"loss\", reuse = tf.AUTO_REUSE):\n","    logits = BiLSTM.logits(X, BiLSTM.W, BiLSTM.b, seq_len)\n","    loss, optimizer = BiLSTM.model_build(logits, Y, learning_rate)\n","\n","prediction = tf.nn.softmax(logits)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-5-ae8abc05ec34>:7: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-5-ae8abc05ec34>:23: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y_NhHKGxCmXR","colab_type":"code","colab":{}},"source":["def Convert2Vec(model_name, sentence):\n","    \n","    word_vec = []\n","    sub = []\n","    model = gensim.models.word2vec.Word2Vec.load(model_name)\n","    for word in sentence:\n","        if(word in model.wv.vocab):\n","            sub.append(model.wv[word])\n","        else:\n","            sub.append(np.random.uniform(-0.25,0.25,300)) ## used for OOV words\n","    word_vec.append(sub)\n","    return word_vec"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIOsezIWCoGr","colab_type":"code","colab":{}},"source":["saver = tf.train.Saver()\n","init = tf.global_variables_initializer()\n","modelName = \"/content/gdrive/My Drive/Colab Notebooks/GraduationProject/Bi_LSTM/BiLSTM_model_Epoch_13.ckpt\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Flq68SSsCpoz","colab_type":"code","outputId":"b228a659-2747-4fc9-d786-5fa0c247c9ce","executionInfo":{"status":"ok","timestamp":1587485223475,"user_tz":-540,"elapsed":4531,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sess = tf.Session()\n","sess.run(init)\n","saver.restore(sess, modelName)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/GraduationProject/Bi_LSTM/BiLSTM_model_Epoch_13.ckpt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"edmVsQwLCq8-","colab_type":"code","colab":{}},"source":["def Grade(sentence):\n","\n","    tokens = W2V.tokenize(sentence)\n","    \n","    embedding = Convert2Vec('/content/gdrive/My Drive/Colab Notebooks/GraduationProject/Word2Vec/Word2vec.model', tokens)\n","    zero_pad = W2V.Zero_padding(embedding, Batch_size, Maxseq_length, Vector_size)\n","    global sess\n","    result =  sess.run(tf.argmax(prediction,1), feed_dict = {X: zero_pad , seq_len: [len(tokens)] } ) \n","    if(result == 1):\n","        print(\"Positive Sentence\")\n","    else:\n","        print(\"Negative Sentence\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kYH9ugtTbVu5","colab_type":"text"},"source":["# **Input the Korean corpus only**"]},{"cell_type":"code","metadata":{"id":"nzSZSxNQCu5q","colab_type":"code","outputId":"f0168c56-39c4-4bcc-91c3-44db6eb93850","executionInfo":{"status":"error","timestamp":1586716142142,"user_tz":-540,"elapsed":4958,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["while(1):\n","    s = input(\"Write the Korean Sentence : \")\n","    if(s == str(1)):\n","        break\n","    else:\n","        Grade(s)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Write the Korean Sentence : 오늘 날씨가 좋아\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6e_E9l7kDij0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}