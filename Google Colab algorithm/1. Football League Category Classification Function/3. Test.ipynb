{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3. Test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMBY2OjDSRjXzM9DoPSR4JI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RT9FIHyOXYj5","colab_type":"code","outputId":"5316c02b-151b-473d-d740-16e0cdf6f244","executionInfo":{"status":"ok","timestamp":1587965594854,"user_tz":-540,"elapsed":720,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9lbax7F3XdhT","colab_type":"code","outputId":"b70fbb77-5f15-4b28-f450-48b061976ae9","executionInfo":{"status":"ok","timestamp":1587965600820,"user_tz":-540,"elapsed":3747,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["!pip install konlpy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n","Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n","Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.3)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n","Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2020.4.5.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IU7KUed3XnAD","colab_type":"code","outputId":"a3418246-49c3-4c78-ed71-79aab8ba6cd8","executionInfo":{"status":"ok","timestamp":1587965604090,"user_tz":-540,"elapsed":2568,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x\n","import os\n","import tensorflow as tf\n","import gensim\n","import numpy as np\n","import csv\n","from konlpy.tag import Okt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jmjT5J2YXtQ3","colab_type":"code","colab":{}},"source":["class Word2Vec():\n","    \n","    def __init__(self):\n","        None\n","\n","    def tokenize(self, doc):\n","        pos_tagger = Okt()\n","        return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n","    \n","    def read_data(self, filename):\n","        with open(filename, 'r',encoding='utf-8') as f:\n","            data = [line.split('\\t') for line in f.read().splitlines()]\n","            data = data[1:]\n","        return data  \n","    \n","    def Word2vec_model(self, model_name):\n","        \n","        model = gensim.models.word2vec.Word2Vec.load(model_name)\n","        return model\n","    \n","    def Convert2Vec(self, model_name, doc): # Convert corpus into vectors\n","        #train_X_ = W2V.Convert2Vec(\"Word2Vec_csv_article.embedding\",train_X)\n","        word_vec = []\n","        model = gensim.models.word2vec.Word2Vec.load(model_name)\n","        for sent in doc:\n","            sub = []\n","            for word in sent:\n","                if word in model.wv.vocab:\n","                    sub.append(model.wv[word]) # Word Vector Input\n","                else:\n","                    sub.append(np.random.uniform(-0.25,0.25,300)) # used for OOV words\n","            word_vec.append(sub)\n","        \n","        return word_vec\n","    \n","    def Zero_padding(self, train_batch_X, Batch_size, Maxseq_length, Vector_size):\n","        \n","        zero_pad = np.zeros((Batch_size, Maxseq_length, Vector_size))\n","        for i in range(Batch_size):\n","            zero_pad[i,:np.shape(train_batch_X[i])[0],:np.shape(train_batch_X[i])[1]] = train_batch_X[i]\n","        return zero_pad\n","    \n","    def One_hot(self, data):\n","       \n","        index_dict = {value:index for index,value in enumerate(set(data))}\n","        result = []\n","        \n","        for value in data:\n","            \n","            one_hot = np.zeros(len(index_dict))\n","            index = index_dict[value]\n","            one_hot[index] = 1\n","            result.append(one_hot)\n","        \n","        return result\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GwrxC5vMXtw_","colab_type":"code","colab":{}},"source":["class Bi_LSTM():\n","    \n","    def __init__(self, lstm_units, num_class, keep_prob):\n","        \n","        self.lstm_units = lstm_units\n","        \n","        with tf.variable_scope('forward', reuse = tf.AUTO_REUSE):\n","            \n","            self.lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(lstm_units, forget_bias=1.0, state_is_tuple=True)\n","            self.lstm_fw_cell = tf.contrib.rnn.DropoutWrapper(self.lstm_fw_cell, output_keep_prob = keep_prob)\n","            \n","        with tf.variable_scope('backward', reuse = tf.AUTO_REUSE):\n","            \n","            self.lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(lstm_units, forget_bias=1.0, state_is_tuple=True)\n","            self.lstm_bw_cell = tf.contrib.rnn.DropoutWrapper(self.lstm_fw_cell, output_keep_prob = keep_prob)\n","        \n","        with tf.variable_scope('Weights', reuse = tf.AUTO_REUSE):\n","           \n","            self.W = tf.get_variable(name=\"W\", shape=[2 * lstm_units, num_class],\n","                                dtype=tf.float32, initializer = tf.contrib.layers.xavier_initializer())\n","            self.b = tf.get_variable(name=\"b\", shape=[num_class], dtype=tf.float32,\n","                                initializer=tf.zeros_initializer())\n","            \n","            \n","    def logits(self, X, W, b, seq_len):\n","        \n","        (output_fw, output_bw), states = tf.nn.bidirectional_dynamic_rnn(self.lstm_fw_cell, self.lstm_bw_cell,dtype=tf.float32,\n","                                                                            inputs = X, sequence_length = seq_len)\n","        ## concat fw, bw final states\n","        outputs = tf.concat([states[0][1], states[1][1]], axis=1)\n","        pred = tf.matmul(outputs, W) + b        \n","        return pred\n","        \n","    def model_build(self, logits, labels, learning_rate = 0.001):\n","        \n","        with tf.variable_scope(\"loss\"):\n","            \n","            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits , labels = labels)) # Softmax loss\n","            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss) # Adam Optimizer\n","            \n","        return loss, optimizer\n","    \n","    def graph_build(self, avg_loss, avg_acc):\n","        \n","        tf.summary.scalar('Loss', avg_loss)\n","        tf.summary.scalar('Accuracy', avg_acc)\n","        merged = tf.summary.merge_all()\n","        return merged\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWJKZZ86XvO3","colab_type":"code","colab":{}},"source":["def Convert2Vec(model_name, sentence):\n","    word_vec = []\n","    sub = []\n","    model = gensim.models.word2vec.Word2Vec.load(model_name)\n","    for word in sentence:\n","        if (word in model.wv.vocab):\n","            sub.append(model.wv[word])\n","        else:\n","            sub.append(np.random.uniform(-0.25, 0.25, 300))  # used for OOV words\n","    word_vec.append(sub)\n","    return word_vec\n","\n","W2V = Word2Vec()\n","\n","def Grade(sentence):\n","    tokens = W2V.tokenize(sentence)\n","    print(tokens)\n","    embedding = Convert2Vec('/content/gdrive/My Drive/Colab Notebooks/GraduationProject/soccer_category/league_category.embedding', tokens)\n","    zero_pad = W2V.Zero_padding(embedding, Batch_size, Maxseq_length, Vector_size)\n","    global sess\n","    result = sess.run(prediction, feed_dict={X: zero_pad, seq_len: [len(tokens)]}) # tf.argmax(prediction, 1)이 여러 prediction 값중 max 값 1개만 가져옴\n","    point = result.ravel().tolist()\n","    Tag = [\"EPL : \", \"LaLiga : \", \"Bundesliga : \", \"Seria : \"]\n","    for t, i in zip(Tag, point):\n","        print(t, round(i * 100, 2),\"%\")\n","        percent = t + str(round(i * 100, 2)) + \"%\"\n","    #     text.write(percent)\n","    #     text.write(\"\\n\")\n","    # text.write(\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gksjwJ_JYCzl","colab_type":"code","colab":{}},"source":["Batch_size = 1\n","Vector_size = 300\n","Maxseq_length = 500  # Max length of training data\n","learning_rate = 0.001\n","lstm_units = 128\n","num_class = 4\n","keep_prob = 1.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hSBg9JBDYG6Y","colab_type":"code","outputId":"af6ada33-450c-4a68-93e5-941e93639d17","executionInfo":{"status":"ok","timestamp":1587963235570,"user_tz":-540,"elapsed":3173,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["X = tf.placeholder(tf.float32, shape = [None, Maxseq_length, Vector_size], name = 'X')\n","Y = tf.placeholder(tf.float32, shape = [None, num_class], name = 'Y')\n","seq_len = tf.placeholder(tf.int32, shape = [None])\n","\n","BiLSTM = Bi_LSTM(lstm_units, num_class, keep_prob)\n","\n","with tf.variable_scope(\"loss\", reuse = tf.AUTO_REUSE):\n","    logits = BiLSTM.logits(X, BiLSTM.W, BiLSTM.b, seq_len)\n","    loss, optimizer = BiLSTM.model_build(logits, Y, learning_rate)\n","\n","prediction = tf.nn.softmax(logits)  # softmax"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-6-c431298b23e5>:9: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-6-c431298b23e5>:28: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sdcxv-gWYKYP","colab_type":"code","outputId":"5ee2e264-95b3-4ba6-dd65-603916bc4b29","executionInfo":{"status":"error","timestamp":1587964927191,"user_tz":-540,"elapsed":749,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["saver = tf.train.Saver()\n","init = tf.global_variables_initializer()\n","modelName = \"/content/gdrive/My Drive/Colab Notebooks/GraduationProject/soccer_category/BiLSTM.model\"\n","\n","sess = tf.Session()\n","sess.run(init)\n","saver.restore(sess, modelName)\n","\n","while(True):\n","    try:\n","        s = input(\"문장을 입력하세요 : \")\n","        Grade(s)\n","    except:\n","        pass"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6edacef526ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gdrive/My Drive/Colab Notebooks/GraduationProject/soccer_category/BiLSTM.model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]},{"cell_type":"code","metadata":{"id":"HGdRrmxRYTOH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}