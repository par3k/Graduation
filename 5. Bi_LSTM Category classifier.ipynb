{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5. Category classifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPPQl4Ur+dT0hunsf1pYnU+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"nZdyYNlTA4P6","colab_type":"code","outputId":"04aa5c8c-b5b9-4f9d-80e3-3d2ffdcd0a5b","executionInfo":{"status":"ok","timestamp":1587106293546,"user_tz":-540,"elapsed":43909,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VvKSMHgMA6Xa","colab_type":"code","outputId":"2518a9c3-2dc0-460a-e634-d379487d9089","executionInfo":{"status":"ok","timestamp":1587106306732,"user_tz":-540,"elapsed":8790,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":581}},"source":["!pip install konlpy"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.2)\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 11.0MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/3c/1dbe5d6943b5c68e8df17c8b3a05db4725eadb5c7b7de437506aa3030701/JPype1-0.7.2-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n","\u001b[K     |████████████████████████████████| 2.4MB 49.4MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Collecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n","Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2020.4.5.1)\n","Installing collected packages: beautifulsoup4, JPype1, colorama, tweepy, konlpy\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","Successfully installed JPype1-0.7.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JIdbtRYS_zbL","colab_type":"code","outputId":"99510045-0b05-40ce-a550-1f709ef46f2e","executionInfo":{"status":"ok","timestamp":1587106314546,"user_tz":-540,"elapsed":5722,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x\n","import os\n","import tensorflow as tf\n","import gensim\n","import numpy as np\n","import csv\n","from konlpy.tag import Okt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EJND7kkYBrO3","colab_type":"code","outputId":"d125ea30-5b34-4ca6-9c7d-df171144a8c1","executionInfo":{"status":"ok","timestamp":1587024543038,"user_tz":-540,"elapsed":2363,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.15.2'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"PRbCRyhGAKHy","colab_type":"code","colab":{}},"source":["class Word2Vec():\n","    \n","    def __init__(self):\n","        None\n","\n","    def tokenize(self, doc):\n","        pos_tagger = Okt()\n","        return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n","    \n","    def read_data(self, filename):\n","        with open(filename, 'r',encoding='utf-8') as f:\n","            data = [line.split('\\t') for line in f.read().splitlines()]\n","            data = data[1:]\n","        return data  \n","    \n","    def Word2vec_model(self, model_name):\n","        \n","        model = gensim.models.word2vec.Word2Vec.load(model_name)\n","        return model\n","    \n","    def Convert2Vec(self, model_name, doc): # Convert corpus into vectors\n","        #train_X_ = W2V.Convert2Vec(\"Word2Vec_csv_article.embedding\",train_X)\n","        word_vec = []\n","        model = gensim.models.word2vec.Word2Vec.load(model_name)\n","        for sent in doc:\n","            sub = []\n","            for word in sent:\n","                if word in model.wv.vocab:\n","                    sub.append(model.wv[word]) # Word Vector Input\n","                else:\n","                    sub.append(np.random.uniform(-0.25,0.25,300)) # used for OOV words\n","            word_vec.append(sub)\n","        \n","        return word_vec\n","    \n","    def Zero_padding(self, train_batch_X, Batch_size, Maxseq_length, Vector_size):\n","        \n","        zero_pad = np.zeros((Batch_size, Maxseq_length, Vector_size))\n","        for i in range(Batch_size):\n","            zero_pad[i,:np.shape(train_batch_X[i])[0],:np.shape(train_batch_X[i])[1]] = train_batch_X[i]\n","        return zero_pad\n","    \n","    def One_hot(self, data):\n","       \n","        index_dict = {value:index for index,value in enumerate(set(data))}\n","        result = []\n","        \n","        for value in data:\n","            \n","            one_hot = np.zeros(len(index_dict))\n","            index = index_dict[value]\n","            one_hot[index] = 1\n","            result.append(one_hot)\n","        \n","        return result\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XftFGSBAbvQ","colab_type":"code","colab":{}},"source":["class Bi_LSTM():\n","    \n","    def __init__(self, lstm_units, num_class, keep_prob):\n","        \n","        self.lstm_units = lstm_units\n","        \n","        with tf.variable_scope('forward', reuse = tf.AUTO_REUSE):\n","            \n","            self.lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(lstm_units, forget_bias=1.0, state_is_tuple=True)\n","            self.lstm_fw_cell = tf.contrib.rnn.DropoutWrapper(self.lstm_fw_cell, output_keep_prob = keep_prob)\n","            \n","        with tf.variable_scope('backward', reuse = tf.AUTO_REUSE):\n","            \n","            self.lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(lstm_units, forget_bias=1.0, state_is_tuple=True)\n","            self.lstm_bw_cell = tf.contrib.rnn.DropoutWrapper(self.lstm_fw_cell, output_keep_prob = keep_prob)\n","        \n","        with tf.variable_scope('Weights', reuse = tf.AUTO_REUSE):\n","           \n","            self.W = tf.get_variable(name=\"W\", shape=[2 * lstm_units, num_class],\n","                                dtype=tf.float32, initializer = tf.contrib.layers.xavier_initializer())\n","            self.b = tf.get_variable(name=\"b\", shape=[num_class], dtype=tf.float32,\n","                                initializer=tf.zeros_initializer())\n","            \n","            \n","    def logits(self, X, W, b, seq_len):\n","        \n","        (output_fw, output_bw), states = tf.nn.bidirectional_dynamic_rnn(self.lstm_fw_cell, self.lstm_bw_cell,dtype=tf.float32,\n","                                                                            inputs = X, sequence_length = seq_len)\n","        ## concat fw, bw final states\n","        outputs = tf.concat([states[0][1], states[1][1]], axis=1)\n","        pred = tf.matmul(outputs, W) + b        \n","        return pred\n","        \n","    def model_build(self, logits, labels, learning_rate = 0.001):\n","        \n","        with tf.variable_scope(\"loss\"):\n","            \n","            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits , labels = labels)) # Softmax loss\n","            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss) # Adam Optimizer\n","            \n","        return loss, optimizer\n","    \n","    def graph_build(self, avg_loss, avg_acc):\n","        \n","        tf.summary.scalar('Loss', avg_loss)\n","        tf.summary.scalar('Accuracy', avg_acc)\n","        merged = tf.summary.merge_all()\n","        return merged\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZKnqGC6_7IZ","colab_type":"code","colab":{}},"source":["\n","def Convert2Vec(model_name, sentence):\n","    word_vec = []\n","    sub = []\n","    model = gensim.models.word2vec.Word2Vec.load(model_name)\n","    for word in sentence:\n","        if (word in model.wv.vocab):\n","            sub.append(model.wv[word])\n","        else:\n","            sub.append(np.random.uniform(-0.25, 0.25, 300))  # used for OOV words\n","    word_vec.append(sub)\n","    return word_vec\n","\n","W2V = Word2Vec()\n","\n","def Grade(sentence):\n","    tokens = W2V.tokenize(sentence)\n","\n","    embedding = Convert2Vec('/content/gdrive/My Drive/Colab Notebooks/GraduationProject/categoryclassifier/Bi_LSTM/Data/post.embedding', tokens)\n","    zero_pad = W2V.Zero_padding(embedding, Batch_size, Maxseq_length, Vector_size)\n","    global sess\n","    result = sess.run(prediction, feed_dict={X: zero_pad, seq_len: [len(tokens)]}) # tf.argmax(prediction, 1)이 여러 prediction 값중 max 값 1개만 가져옴\n","    point = result.ravel().tolist()\n","    Tag = [\"IT과학\", \"경제\", \"정치\", \"e스포츠\", \"골프\", \"농구\", \"배구\", \"야구\", \"일반 스포츠\", \"축구\", \"사회\", \"생활문화\"]\n","    for t, i in zip(Tag, point):\n","        print(t, round(i * 100, 2),\"%\")\n","        percent = t + str(round(i * 100, 2)) + \"%\"\n","        #text.write(percent)\n","        #text.write(\"\\n\")\n","    #text.write(\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yft3y2UCAm2H","colab_type":"code","colab":{}},"source":["Batch_size = 1\n","Vector_size = 300\n","Maxseq_length = 500  # Max length of training data\n","learning_rate = 0.001\n","lstm_units = 128\n","num_class = 12\n","keep_prob = 1.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7nsJh5z0AqDH","colab_type":"code","outputId":"f6981f49-c23d-4e37-b2fc-63692bf319e6","executionInfo":{"status":"ok","timestamp":1587106328879,"user_tz":-540,"elapsed":3272,"user":{"displayName":"박회재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLNtW3cEP6ijcjRJLZBANmZYUyTrHXcKJWEGtNDA=s64","userId":"17044052781042873598"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["X = tf.placeholder(tf.float32, shape = [None, Maxseq_length, Vector_size], name = 'X')\n","Y = tf.placeholder(tf.float32, shape = [None, num_class], name = 'Y')\n","seq_len = tf.placeholder(tf.int32, shape = [None])\n","\n","BiLSTM = Bi_LSTM(lstm_units, num_class, keep_prob)\n","\n","with tf.variable_scope(\"loss\", reuse = tf.AUTO_REUSE):\n","    logits = BiLSTM.logits(X, BiLSTM.W, BiLSTM.b, seq_len)\n","    loss, optimizer = BiLSTM.model_build(logits, Y, learning_rate)\n","\n","prediction = tf.nn.softmax(logits)  # softmax"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-6-c431298b23e5>:9: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-6-c431298b23e5>:28: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UroV9LbZAsrn","colab_type":"code","outputId":"9c5e1da3-174c-4e56-a76d-b50e2d897db9","colab":{"base_uri":"https://localhost:8080/","height":327}},"source":["saver = tf.train.Saver()\n","init = tf.global_variables_initializer()\n","modelName = \"/content/gdrive/My Drive/Colab Notebooks/GraduationProject/categoryclassifier/Bi_LSTM/Data/Bi_LSTM.model\"\n","sess = tf.Session()\n","sess.run(init)\n","saver.restore(sess, modelName)\n","\n","while(True):\n","    try:\n","        s = input(\"문장을 입력하세요 : \")\n","        Grade(s)\n","    except:\n","        pass"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/GraduationProject/categoryclassifier/Bi_LSTM/Data/Bi_LSTM.model\n","문장을 입력하세요 : '양대포털' 카카오-네이버도 출근…'재택 해제' 기지개 켜는 판교\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["IT과학 87.1 %\n","경제 10.08 %\n","정치 0.88 %\n","e스포츠 0.29 %\n","골프 0.12 %\n","농구 0.0 %\n","배구 0.0 %\n","야구 0.0 %\n","일반 스포츠 0.01 %\n","축구 0.03 %\n","사회 0.83 %\n","생활문화 0.66 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hE6j2KcvCMIK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}